# -*- coding: utf-8 -*-
"""RAG Q&A Chatbot for Loan Approval Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h9FkQZSI78azon4-qsFnBBg1sw0OwjRq
"""

import pandas as pd

df = pd.read_csv("Training Dataset.csv")
df.fillna("NA", inplace=True)
df.head()

documents = []
for index, row in df.iterrows():
    doc = f"Applicant {row['Loan_ID']} with gender {row['Gender']} and income {row['ApplicantIncome']} requested a loan of {row['LoanAmount']}. Loan Status: {row['Loan_Status']}"
    documents.append(doc)

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

model = SentenceTransformer('all-MiniLM-L6-v2')  # lightweight and fast

# Convert documents to embeddings
embeddings = model.encode(documents)

# Build FAISS index
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings))

def search(query, k=3):
    query_embedding = model.encode([query])
    distances, indices = index.search(np.array(query_embedding), k)
    return [documents[i] for i in indices[0]]

import openai
openai.api_key = "your_openai_api_key"

def generate_response(context, query):
    prompt = f"Use the following information to answer:\n{context}\n\nQuestion: {query}\nAnswer:"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return response['choices'][0]['message']['content']

def rag_qa_bot(query):
    relevant_docs = search(query)
    context = "\n".join(relevant_docs)
    answer = generate_response(context, query)
    return answer

import streamlit as st

st.title("ðŸ“Š Loan Dataset RAG Q&A Chatbot")

user_query = st.text_input("Ask a question about the loan dataset:")

if st.button("Get Answer"):
    with st.spinner("Searching and thinking..."):
        answer = rag_qa_bot(user_query)
        st.success(answer)
import os
import openai

openai.api_key = os.getenv("OPENAI_API_KEY")
